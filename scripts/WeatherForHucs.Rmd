---
title: "Weather for Hucs"
author: "Anna Talucci"
date: "11/18/2023"
output: html_document
---



# Overview

Filter weather data extracted from EE. Join weather data to Hucs. Convert from .shp to .json.

Select daily weather based on 200 highest temperature days.

SC test huc huc12==180701060203

Name variables
temperature
relative-humidity
wind-speed-20ft
wind-from-direction
foliar-moisture
fuel-moisture
dead
1hr
10hr
100hr
live
herbaceous
woody

```{r eval=FALSE, include=FALSE}
setdiff( scHuc$huc12, df$huc12)
```

# Global options
prevent scientific notation; use =0 to reset
```{r}
options(scipen=999)
```

# Packages
```{r}
library('tidyverse')
library('sf')
library('jsonlite')
```

# Data


## HUCs
## HUC Shapefiles
TxHucScCc.shp
```{r}
hucs = st_read("../data/TxHucs/TxPrctRankRrkWipRffc.shp", "TxPrctRankRrkWipRffc")
```


```{r}
scHuc = hucs %>% filter(RRK_Rgn == "South Coast Region")
ccHuc = hucs %>% filter(RRK_Rgn == "Central Coast Region")
```

## CSV weather data
output from GEE
```{r}
list <- list.files(path="../data/weather/timestep1524/sc", pattern='csv$', full.names = TRUE)
```
```{r}
list
```
# Function to combine CSV
## Combine, Clean, and organize
```{r}
combineCsv <- function(list){
  purrr::map(list, read.csv) %>%
  bind_rows() %>%
    dplyr::select(-system.index, -.geo) 
}
```

## Apply cobine function
```{r}
df = combineCsv(list)
```

```{r}
df
```

```{r}
df1 = df%>%
    pivot_longer(cols = starts_with("GF"),
    names_to = "variable",
    values_to = "value", 
    values_drop_na = TRUE) %>%
    separate(col=variable, into=c("model","scenario","date", "climate"), sep="_", fill="right")  %>%
    pivot_wider(names_from = climate, values_from = value) %>%
    mutate(tasmax = ((tasmax-273.15)*9/5+32)) %>%
    rename(temperature=tasmax, relative.humidity=rhsmin, wind.speed.20ft=ws, wind.from.direction=wd) 
```

```{r}
df1
```
## Filter for Temp
```{r}
temp <- function(x){
  x %>% 
    group_by(RRK_Rgn, huc12) %>%
    arrange(desc(temperature)) %>%
    top_n(n=200)
}
```

## Apply temp function
```{r}
df2 = temp(df1)
```


# WORKING HERE!!! Weather - fuel to json
```{r}
( 
  a = df2 %>% 
  ungroup()%>%
    filter(huc12==180701060203) %>% 
  mutate(foliar.moisture=82.2) %>%
    mutate(dead.1hr=0.02) %>%
  mutate(dead.10hr = 0.02) %>%
  mutate(dead.100hr=0.02) %>%
  mutate(live.herbaceous = 0.34) %>%
  mutate(live.woody = 0.67) %>%
  dplyr::select(-RRK_Rgn, -model, -scenario) %>%
    pivot_longer(cols = starts_with("dead"),
    names_to = "variable",
    values_to = "value") %>% 
    separate(col=variable, into=c("x","y"), sep="\\.") %>%
    pivot_wider(names_from = y, values_from = value) %>%
    group_by(date) %>%
    nest(data=c('1hr', '10hr', '100hr')) %>%
    rename(dead=data) %>%
    dplyr::select(-x) %>%
    pivot_longer(cols = starts_with("live"),
    names_to = "variable",
    values_to = "value") %>% 
    separate(col=variable, into=c("x","y"), sep="\\.") %>%
    pivot_wider(names_from = y, values_from = value) %>%
    nest(data=c(herbaceous, woody)) %>%
    rename(live=data) %>%
    dplyr::select(-x) %>%
    nest(data=c(dead, live)) %>%
    rename(fuel.moisture=data) %>%
    nest(data=c(temperature, relative.humidity, wind.from.direction, wind.speed.20ft, foliar.moisture, fuel.moisture)) %>%
  jsonlite::toJSON(auto_unbox = TRUE, pretty = TRUE) 
    
  
  )
  
```

  
```{r eval=FALSE, include=FALSE}
a %>%
  jsonlite::toJSON(auto_unbox = TRUE, pretty = TRUE) 
```

```{r}
write(a, "../outputs/jsonHuc/180701060203.json")
```



#THESE LOOPS WORK BUT NEED TO BE ADAPTED FOR FORMATING THE JSON
## SC
```{r}

uni <- unique(scShp[,c("huc12")])

for (j in 1:nrow(uni)) {
  i <- uni[j,]
  tmp <- scShp %>% filter(huc12 == i$huc12)
  st_write(tmp, dsn = paste("../outputs/singleHucShp/sc/", i$huc12, '.shp'), driver="ESRI Shapefile", overwrite_layer=TRUE)
}
  
```


## CC
```{r}

uni <- unique(ccShp[,c("huc12")])

for (j in 1:nrow(uni)) {
  i <- uni[j,]
  tmp <- ccShp %>% filter(huc12 == i$huc12)
  st_write(tmp, dsn = paste("../outputs/singleHucShp/cc/", i$huc12, '.shp'), driver="ESRI Shapefile", overwrite_layer=TRUE)
}
  
```

## For GEoJson
### Sc
```{r}

uni <- unique(scShp[,c("huc12")])

for (j in 1:nrow(uni)) {
  i <- uni[j,]
  tmp <- scShp %>% filter(huc12 == i$huc12)
  st_write(tmp, dsn = paste("../outputs/jsonHuc/sc/", i$huc12, '.geojson'), driver="GeoJSON", overwrite_layer=TRUE)
}
  
```

### Cc
```{r}

uni <- unique(ccShp[,c("huc12")])

for (j in 1:nrow(uni)) {
  i <- uni[j,]
  tmp <- ccShp %>% filter(huc12 == i$huc12)
  st_write(tmp, dsn = paste("../outputs/jsonHuc/cc/", i$huc12, '.geojson'), driver="GeoJSON", overwrite_layer=TRUE)
}
  
```






# DOES NOT WORK
splitByAttributes = function(spdata, codename, dsn=getwd()){
CODES <- unique(spdata[[codename]])
for (i in 1:length(CODES)) {
  tmp <- spdata[spdata[[codename]] == CODES[i], ]
  writeOGR(tmp, dsn=dsn, CODES[i], driver="ESRI Shapefile",
           overwrite_layer=TRUE)
  }
}

file = paste("./output/", cn ,"data.txt", sep = "")
```{r}
splitByAttributes = function(spdata, huc12){
CODES <- unique(spdata[[huc12]])
for (i in 1:length(CODES)) {
  tmp <- spdata[spdata[[huc12]] == CODES[i], ]
  st_write(tmp, file=paste("../outputs/singleHucShp/", CODES[i], ".shp"), driver="ESRI Shapefile", overwrite_layer=TRUE)
  }
}
```


```{r}
splitByAttributes(scShp, scShp$huc12)

```

```{r}
unique <- unique(scShp$huc12)

#create new polygons based on the determined column
for (i in 1:length(unique)) {
  tmp <- scShp[scShp$huc12 == unique[i], ]
  st_write(tmp, dsn = "../outputs/singleHucShp/", unique[i], driver="ESRI Shapefile", overwrite_layer=TRUE)
  
}
```



for (j in 1:nrow(uni)) {
  i <- uni[j,]
  tmp <- x %>% filter(Model == i$Model, Garage == i$Garage, City == i$City)

  write.table(tmp, paste(i$Model, "_", i$City, "_", i$Garage, ".csv"))
}


```{r}
test  = scShp %>% st_cast("POLYGON") %>% filter(huc12==180300031404) 
```

**THE END**