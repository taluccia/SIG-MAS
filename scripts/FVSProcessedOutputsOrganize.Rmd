---
title: "Summary FVS Processed Outputs"
author: "Anna Talucci"
date: "12/2/2023"
output: html_document
---

```{r clearEnvironment, include=FALSE}
rm(list=ls())
```

```{r globalOptions, include=FALSE}
options(scipen=999) #Prevent scientific notation of numeric values; use =0 to reset
```

# Overview

Takes outputs from FVS and clean the HUC12 level data so that the FVS output data csv file has been update for 2837 HUC12s across four RRK Regions (Central Coast Region [435], North Coast Region [774], Sierra Nevada Region [1148], South Coast Region [480]). Each HUC has output data for the combination of three Priorities, three Treatment Intensities, three treatments types, and four time steps, which results in a data table with 306,396 rows.


# Library
```{r}
library(tidyverse)
library(sf)
library(vroom)
library(tidyr)
```


# HUC Data
```{r}
huc = st_read("../data/spatialDataCreateShp/TxHucs/TxPrctRankRrkWipRffc.shp", "TxPrctRankRrkWipRffc")
```

```{r}
huc %>% st_drop_geometry() %>% group_by(RRK_Rgn) %>% summarise(n=n())
```

```{r}
huc
```

```{r}
unique(huc$RRK_Rgn)
```

```{r}
unique(huc$Priorty)
```

```{r}
unique(huc$TxWPrct)
```
```{r}
names(huc)
```
```{r}
(hucs = huc %>%  
    dplyr::select(-c('WIPGeNm',"WIP_Cpc",  "BpRnkWp",  "WuRnkWp",  "BpPrctW",  "WPrctWp")) %>%
   rename(wuiGroup = TxWPrct, fireGroup = TxBpPrc, hybridGroup = TxRffcP, regionName = RRK_Rgn, hybridPrty=Priorty, hybridVal=rffc, hybridRnk=rffcRnk, hybridPrct =rffcPrc)
 )

```

## Rename and additions to HUC data
"Sierra Nevada Region" "North Coast Region"   "Central Coast Region" "South Coast Region"  
```{r}
( attributeAdds = huc %>%  
    dplyr::select(-c('WIPGeNm',"WIP_Cpc",  "BpRnkWp",  "WuRnkWp",  "BpPrctW",  "WPrctWp")) %>%
   rename(wuiGroup = TxWPrct, fireGroup = TxBpPrc, hybridGroup = TxRffcP, regionName = RRK_Rgn, hybridPrty=Priorty, hybridVal=rffc, hybridRnk=rffcRnk, hybridPrct =rffcPrc) %>%

  mutate(region = ifelse(regionName == "Sierra Nevada Region", "SN",
                ifelse(regionName == "North Coast Region" , "NC",
              ifelse(regionName == "South Coast Region" , "SC", 
                    ifelse(regionName == "Central Coast Region" , "CC", "NA"))))) %>%
    mutate(timeWui= ifelse(wuiGroup == 25, "2024_yr1to5_16to20",
                    ifelse(wuiGroup == 50 , "2029_yr6to10",
                    ifelse(wuiGroup == 75 , "2034_yr11to15", "notTreated")))) %>%
    mutate(timeFire = ifelse(fireGroup == 25, "2024_yr1to5",
                      ifelse(fireGroup == 50 , "2029_yr6to10",
                      ifelse(fireGroup == 75 , "2034_yr11to15", "2039_yr16to20")))) %>% 
    mutate(timeHybrid = ifelse(hybridGroup == 25, "2024_yr1to5",
                    ifelse(hybridGroup == 50 , "2029_yr6to10",
                     ifelse(hybridGroup == 75 , "2034_yr11to15", "2039_yr16to20")))) %>%
  dplyr::select(huc12:hybridGroup, region:timeHybrid, geometry)
)
```


# Write 
```{r eval=FALSE, include=FALSE}
st_write(attributeAdds, "../outputs/boundaries/hucsShp/TxHucsTimingGroups.shp", driver="ESRI Shapefile")
```


```{r}
unique(attributeAdds$regionName)
unique(attributeAdds$region)
```

## Subset by region

```{r}
( snOrg = attributeAdds %>% st_drop_geometry() %>% filter(region=="SN") )
( ncOrg = attributeAdds %>% st_drop_geometry() %>% filter(region=="NC") )
( scOrg = attributeAdds %>% st_drop_geometry() %>% filter(region=="SC") )
( ccOrg = attributeAdds %>% st_drop_geometry() %>% filter(region== "CC") )
```




# FVS Processed output Data
List of csv files

```{r}
listBase <- list.files(path="../data/FVS/processed_output/baseline/",pattern='csv$', full.names = TRUE)

listCC <- list.files(path="../data/FVS/processed_output/CC/",pattern='csv$', full.names = TRUE)

listSC <- list.files(path="../data/FVS/processed_output/SC/",pattern='csv$', full.names = TRUE)

listSN <- list.files(path="../data/FVS/processed_output/SN/",pattern='csv$', full.names = TRUE)
```

```{r}
listBase
```

```{r}
listCC
```

```{r}
listSC
```

```{r}
listSN
```

### Name items in a list with file name
```{r}
names(listBase) <- tools::file_path_sans_ext(basename(listBase))
names(listCC) <- tools::file_path_sans_ext(basename(listCC))
names(listSC) <- tools::file_path_sans_ext(basename(listSC))
names(listSN) <- tools::file_path_sans_ext(basename(listSN))
```



```{r}
listBase[1] %>% read.csv()
listCC[1] %>% read.csv()
listSC[1] %>% read.csv()
listSN[1] %>% read.csv()
```

# Functions

Organize dataframe with file name information
```{r}
part1 <- function(list){
  purrr::map(list, read.csv) %>%
    map2(names(.), ~mutate(.x, Tx = .y)) %>%
  bind_rows() %>%
    separate(., Tx, into = c("run", "region", 'Priority', 'Intensity', 'TxType', 'extraName'), sep = '_', convert=TRUE, extra='merge')
}

```

# Apply function to list
```{r}
fvs_Base = part1(listBase)
fvs_cc = part1(listCC)
fvs_sc = part1(listSC)
fvs_sn = part1(listSN)
```


```{r}
fvs_Base
fvs_cc
fvs_sc
fvs_sn
```


# Check Data

```{r}
unique(fvs_cc$TxType)
unique(fvs_cc$TxIntensity)
unique(fvs_cc$Priority)
unique(fvs_cc$run)
```

```{r}
unique(fvs_sc$TxType)
unique(fvs_sc$TxIntensity)
unique(fvs_sc$Priority)
unique(fvs_sc$run)
```

```{r}
unique(fvs_sn$TxType)
unique(fvs_sn$TxIntensity)
unique(fvs_sn$Priority)
unique(fvs_sn$run)
```

```{r}
( new_DF <- fvs_cc[rowSums(is.na(fvs_cc)) > 0,] )

( new_DF <- fvs_sc[rowSums(is.na(fvs_sc)) > 0,] )

( new_DF <- fvs_sn[rowSums(is.na(fvs_sn)) > 0,] )
```


```{r}
fvs_cc
fvs_sc
fvs_sn
```

# Base line organize
```{r}
fvs_Base
```

```{r}
baseline = fvs_Base %>% 
  rename(region1 = run, run1 = region) %>%
  rename(region = region1, run = run1)  %>%
  select(HUC12:run) %>%
  mutate(Priority = "baseline",
         Intensity = "baseline",
         TxType = "baseline") %>%
  mutate(TSC = TSC_x_100/100,
         SDI = SDI_x_100/100,
         QMD = QMD_x_100/100, 
         Fuel_lt3 = Fuel_lt3_x_100/100, 
         Fuel_3to6 = Fuel_3to6_x_100/100,
         Fuel_6to12 = Fuel_6to12_x_100/100) %>%
  rename(huc12=HUC12) %>%
  mutate(huc12 = as.character(huc12)) %>%
dplyr::select(huc12:Year, region:Fuel_6to12)
  
```

## Split base line by region
```{r}
( cc_base = baseline %>% filter(region=="CC") )
( sc_base = baseline %>% filter(region=="SC") )
( sn_base = baseline %>% filter(region=="SN") )
```

## check distinct HUC 12 ids
```{r}
n_distinct(cc_base$huc12)
n_distinct(sc_base$huc12)
n_distinct(sn_base$huc12)
```


# Rescale FVS outputs

## Function

```{r}
rescale <- function(x){
  x %>%
  dplyr::select(HUC12, region:TxType, run, Year:Fuel_6to12_x_100) %>%
  mutate(TSC = TSC_x_100/100,
         SDI = SDI_x_100/100,
         QMD = QMD_x_100/100, 
         Fuel_lt3 = Fuel_lt3_x_100/100, 
         Fuel_3to6 = Fuel_3to6_x_100/100,
         Fuel_6to12 = Fuel_6to12_x_100/100) %>%
  dplyr::select(HUC12:Year, TSC:Fuel_6to12) %>%
  rename(huc12=HUC12) %>%
  mutate(huc12 = as.character(huc12))
}

```

## Apply rescale function
```{r}
rescale_cc = fvs_cc %>% rescale()
rescale_sc = fvs_sc %>% rescale()
rescale_sn = fvs_sn %>% rescale()
```

## check distinct HUC 12 ids
```{r}
n_distinct(rescale_cc$huc12)
n_distinct(rescale_sc$huc12)
n_distinct(rescale_sn$huc12)
```

# Fix duplicate issue and extract HUCs in RRK

Remove Huc12 that are included in the incorrect region because they are on the edge.

```{r}
435+774+1148+480
2837*3*3*3*4
```
Central Coast Region	435			
North Coast Region	774			
Sierra Nevada Region	1148			
South Coast Region	480	

## CC
```{r}
435*3*3*3*4
```

```{r}
(ccOnlyHucs <- filter(rescale_cc,huc12 %in% ccOrg$huc12))
(ccOnlyBaseline <- filter(cc_base,huc12 %in% ccOrg$huc12))
```

## SN

```{r}
1148*3*3*3*4
```

```{r}
(snOnlyHucs <- filter(rescale_sn, huc12 %in% snOrg$huc12))
(snOnlyBaseline <- filter(sn_base,huc12 %in% snOrg$huc12))
```

## SC
### Correct # of rows
```{r}
480*3*3*3*4
```

```{r}
(scOnlyHucs <- filter(rescale_sc, huc12 %in% scOrg$huc12))
(scOnlyBaseline <- filter(sc_base,huc12 %in% scOrg$huc12))
```

## Check unique HUC 12 ids
```{r}
n_distinct(scOnlyHucs$huc12)
n_distinct(scOnlyBaseline$huc12)
n_distinct(ccOnlyHucs$huc12)
n_distinct(ccOnlyBaseline$huc12)
n_distinct(snOnlyHucs$huc12)
n_distinct(snOnlyBaseline$huc12)
```


# Check years
```{r}
unique(scOnlyHucs$Year)
unique(ccOnlyHucs$Year)
unique(snOnlyHucs$Year)
```

## NC

### Correct # of rows
774
```{r}
774*3*3*3*4
```



# Recombine data from the four RRKs
```{r}
435+774+1148+480
2837*3*3*3*4
```

## SC, CC, SN
```{r}
435+1148+480
```

```{r}
2063*3*3*3*4
```

# add orginal HUC variables
```{r}
( scJoin = full_join(scOnlyHucs, scOrg, by="huc12") )
( scJoinBase = full_join(scOnlyBaseline, scOrg, by="huc12") )
```

```{r}
( snJoin = full_join(snOnlyHucs, snOrg, by="huc12") )
( snJoinBase = full_join(snOnlyBaseline, snOrg, by="huc12") )
```

```{r}
( ccJoin = full_join(ccOnlyHucs, ccOrg, by="huc12") )
( ccJoinBase = full_join(ccOnlyBaseline, ccOrg, by="huc12") )
```

# Bind rows together
```{r}
( dataFvs = bind_rows(scJoin, scJoinBase, ccJoin,ccJoinBase, snJoin, snJoinBase) )
```

```{r}
(
dataFvs1 = dataFvs %>%
    dplyr::select(huc12:Fuel_6to12, regionName, hucAc, wuiGroup, fireGroup, hybridGroup, timeWui, timeFire, timeHybrid) %>% rename(region=region.x)
)
```

# Check

```{r}
dataFvs1 %>% group_by(region) %>% 
  summarise(n = n_distinct(huc12))
```

# Column updates for Datacube

* Replace RFFC with Hybrid
* add time step column for per
```{r}
unique(dataFvs$Priority)
```

```{r}
dataFvs2 = dataFvs1 %>% 
  mutate(Priority = str_replace(Priority, 'RFFC', 'Hybrid')) %>%
  mutate(Year = str_replace(Year, '2044', '2039'))
```

```{r}
unique(dataFvs2$Priority)
unique(dataFvs2$Year)
```
# Subset timing and Huc
```{r}

( timing = dataFvs2 %>% dplyr::select(huc12, region, Priority, Intensity, TxType, run, Year, timeFire, timeHybrid, timeWui) )
```

# Write Summary Table
```{r}
write.csv(dataFvs2, "../outputs/fvs/FVSprocessedOutputsHucsScCcSnBase.csv", row.names = F)
```

```{r}
write.csv(timing, "../outputs/fvs/HucTxTiming.csv", row.names = F)
```
